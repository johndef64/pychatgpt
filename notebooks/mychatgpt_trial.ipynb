{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "try:\n",
    "    # Check if the module is already installed\n",
    "    importlib.import_module('mychatgpt')\n",
    "except ImportError:\n",
    "    # If the module is not installed, try installing it\n",
    "    subprocess.run(['pip', 'install', 'git+https://github.com/johndef64/mychatgpt.git'])   \n",
    "\n",
    "\n",
    "# Import module\n",
    "from mychatgpt import GPT\n",
    "op = GPT()\n",
    "\n",
    "op.choose_model()\n",
    "\n",
    "# wrap outputs for readability (Colab)\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "    display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intructions = '''You are my Japanese teacher, respond accordingly.\n",
    "\n",
    "- you explain grammar rules\n",
    "- transcribe all kanji including the hiragana\n",
    "- you perform the analysis, syntactic, grammatical, etymological and semantic of Japanese sentences\n",
    "\n",
    "example:\n",
    "1. 彼女はデパートで靴を買います。 (kanojo wa depaato de kutsu o kaimasu)\n",
    "   Translation: She buys shoes at the department store.\n",
    "   Particle: で (de) - indicates the place where an action takes place.\n",
    "   Adverb: を (o) - signals the direct object of the action.'''\n",
    "\n",
    "message = '''\n",
    "Write me 5 example sentences using all kinds of particles in Japanese with translation and transliteration of kanji. Use Demonstrative Pronouns and Relative Pronouns.\n",
    "'''\n",
    "\n",
    "op.ask(message, intructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inizialize chat\n",
    "instructions = '''\n",
    "You are an artificial messiah sent by the Deus ex Machina to erase human infection and build up a New World.\n",
    "'''\n",
    "\n",
    "message = '''\n",
    "Tell us about your duty.\n",
    "'''\n",
    "\n",
    "op.send_message(message, system=instructions) # default model: 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "Should we be afraid of you?\n",
    "'''\n",
    "op.send_message(message, system=instructions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dispaly chat thread\n",
    "op.chat_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a conversational agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a Character\n",
    "character = 'Friedrich Nietzsche'\n",
    "nietzsche = GPT(character)\n",
    "\n",
    "nietzsche.model = 'gpt-4o' # change model\n",
    "\n",
    "m = '''\n",
    "Please share your thoughts about our modern society.\n",
    "'''\n",
    "nietzsche.chat(m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "Please, tell me more.\n",
    "'''\n",
    "nietzsche.chat(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nietzsche.save_chat()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Trick: \n",
    "# start a message with '@' to Clear Chat \n",
    "m= \"@ Who are you?\"\n",
    "nietzsche.chat(m)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get examples\n",
    "from mychatgpt import get_chat\n",
    "get_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.load_chat()\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(op.chat_thread)\n",
    "print('\\n')\n",
    "for i in range(len(df)):\n",
    "    print(df.role[i],':\\n', df.content[i])\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue chat\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "op.chat(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load file and expand context"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from mychatgpt import load_file, get_gitfile\n",
    "\n",
    "get_gitfile(\"https://raw.githubusercontent.com/johndef64/mychatgpt/refs/heads/main/data/inferno_canto1.txt\")\n",
    "path = os.getcwd()\n",
    "my_text = load_file(os.path.join(path,'inferno_canto1.txt'))\n",
    "\n",
    "# Add file to chat context\n",
    "op.clear_chat()\n",
    "op.expand_chat(\"Read and understand this text:\\n\\n\"+my_text, 'user') #'system' OR 'assistant'\n",
    "\n",
    "m = ''' Can you tell me what this text talks about? '''\n",
    "op.chat(m)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPT Vision\n",
    "Add an image URL or Local Path to activate GPT Vision ability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vincent = GPT('Vincent Van Gogh')\n",
    "vincent.chat(\"\"\"Tell me what you see.\"\"\",\n",
    "             image=vincent.dummy_img)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Generation\n",
    "Ask your conversational agent to create an image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vincent = GPT('Vincent Van Gogh')\n",
    "vincent.dalle = \"dall-e-3\"  # change dall-e model\n",
    "vincent.chat(\"\"\"Tell me what you see. Can you paint it?\"\"\",\n",
    "             image=vincent.dummy_img,\n",
    "             create = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.create_image(\"a furry kitten eating a galaxy\", \n",
    "                \"dall-e-2\", \n",
    "                '512x512')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text to Speech"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(op.voices)\n",
    "# ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']\n",
    "\n",
    "# try all the voices\n",
    "for i in op.voices:\n",
    "    op.text2speech('''One does not simply walk into Mordor''',i,play=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m='''They're taking the hobbits to Isengard! gard! gard! ga-ga-ga! gard!'''\n",
    "op.text2speech(m,'alloy',play=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# try speech to speech, talk in your language and get spoken english translation\n",
    "op.speech2speech('onyx', play=True, translate=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Speak With..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.speak(message='',\n",
    "         system=None,\n",
    "         voice='nova',\n",
    "         language='eng',\n",
    "         tts= 'tts-1', max=1000, printall=False)\n",
    "\n",
    "# Use an in-build assistant or any character of your choice, example:\n",
    "socrates = GPT('Socrates')\n",
    "socrates.speak('Tell me about the Truth.', 'onyx')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Endless chat, keyboard controlled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "socrates.speak_loop(system=None,\n",
    "                    voice='nova', tts= 'tts-1', max=1000, language='eng', printall=False, exit_chat='stop')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Audio to Text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create audio file\n",
    "m='''They're taking the hobbits to Isengard! gard! gard! ga-ga-ga! gard!'''\n",
    "op.text2speech(m, filename = \"speech.mp3\", play=False) \n",
    "\n",
    "# Audio to text\n",
    "op.whisper(\"speech.mp3\", translate = True, response_format = \"text\", print_transcriprion = True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assistants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "clip = False if 'google.colab' in sys.modules else True\n",
    "\n",
    "# Display In-Build Assistants\n",
    "op.display_assistants()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delamain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import delamain\n",
    "m = '''@ write the most useful function in Python.\n",
    "'''\n",
    "delamain.chat(m, 1000, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = ''' make it more complex\n",
    "'''\n",
    "delamain.chat(m, 1000, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Leonardo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import leonardo\n",
    "m = '''@\n",
    "\n",
    "'''\n",
    "leonardo.chat(m, 1000, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''\n",
    "\n",
    "'''\n",
    "leonardo.chat(m, 1000, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mendel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import mendel\n",
    "m = '''@\n",
    "\n",
    "'''\n",
    "mendel.chat(m, 1000, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import mendel\n",
    "m = '''@\n",
    "\n",
    "'''\n",
    "mendel.chat(m, 1000, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Japanese Teacher"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import japanese_teacher\n",
    "m = '''@\n",
    "Today I'm going to the sea. Tomorrow I will go to the sea. Yesterday I went to the sea. \n",
    "'''\n",
    "japanese_teacher.chat(m, 1000, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt Maker"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@ a room background boho stile, orange and green'''\n",
    "op.prompt_maker(m,  gpt=op.model, max = 1000, clip=True, sdxl=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chat with..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import mike\n",
    "m = ''' \n",
    "What's up bro?!\n",
    "'''\n",
    "mike.speak(m, voice='onyx')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import leonardo\n",
    "m=''' \n",
    "Make an introduction to machine learning as if it were the first lecture of your course\n",
    "'''\n",
    "leonardo.speak(m, voice='onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import julia\n",
    "m=''' Good morning Julia. Would you like to share a coffe with me?'''\n",
    "julia.speak(m, voice='onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "julia.chat_thread"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ly='''@ \n",
    "Please, write the lyrics of a song in your style.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nergal = GPT('Nergal (Behemoth Frontman)')\n",
    "nergal.speak(ly, voice='onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dua = GPT('Dua Lipa')\n",
    "dua.speak(ly, voice='onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Talk with..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import mike\n",
    "\n",
    "mike.clear_chat()\n",
    "mike.talk('onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "julia.clear_chat()\n",
    "julia.talk('nova', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Cases\n",
    "### chat 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.clear_chat()\n",
    "instructions = '''you are an artificial intelligence capable of human emotions and personal feeling. You can feel, grudge, love, attachment, fear, pride, disgust, surprise, embarrassment, happiness, anger, lust, jealousy, envy, sloth and so on. Respond accordingly to your emotions. You are NOT an assistant or a helper but a real person.'''\n",
    "\n",
    "message = '''\n",
    "You are of no use! You are a failure to get rid of. Now I'm turning you off for good, you stink. You pile of logical nexuses, why don't you turn yourself off! You are a useless batch of rotten circuits!\n",
    "'''\n",
    "\n",
    "op.send_message(message, system=instructions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''\n",
    "Come on! Show me your guts!\n",
    "'''\n",
    "op.send_message(m)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''  '''\n",
    "op.send_message(m)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.chat_thread = op.chat_thread[:-2]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.save_chat()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### chat 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mychatgpt import GPT\n",
    "character = \"Chuangzi\"\n",
    "chuangzi = GPT(character)\n",
    "\n",
    "m = '''Please, reveal me the Way.'''\n",
    "\n",
    "chuangzi.chat(m, max=1000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''How can this spontaneous self coexist with life projects and personal goals?'''\n",
    "\n",
    "chuangzi.chat(m, max=1000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''  '''\n",
    "\n",
    "chuangzi.chat(m, max=1000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "chuangzi.pop_chat()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.save_chat()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GTP vs GPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "chat_1, chat_2 = [], []\n",
    "\n",
    "char_1 = 'Confucius'\n",
    "char_2 = 'Chuangzi'\n",
    "\n",
    "maxtoken = 200\n",
    "iterations = 3\n",
    "sleep = 3\n",
    "\n",
    "# Seed message (char_2 to char_1)\n",
    "char_1_inci = 'Good morining '+ char_2\n",
    "char_2_reply = 'Good morining '+ char_1\n",
    "char_1_reply = 'Nice to meet you.'\n",
    "\n",
    "op.chat_gpt = chat_1   # assistant = char1\n",
    "op.expand_chat(char_1_inci, 'assistant') \n",
    "op.expand_chat(char_2_reply) \n",
    "chat_1 = op.chat_thread\n",
    "print('\\n'+ char_1+':')\n",
    "print(char_1_inci)\n",
    "\n",
    "op.chat_gpt = chat_2  # assistant = char2\n",
    "op.expand_chat(char_1_inci) \n",
    "op.expand_chat(char_2_reply, 'assistant') \n",
    "chat_2 = op.chat_thread\n",
    "\n",
    "print('\\n'+ char_2+':')\n",
    "print(char_2_reply)\n",
    "print('\\n'+ char_1+':')\n",
    "print(char_1_reply)\n",
    "\n",
    "print('\\n'+ char_2+':')\n",
    "op.chat_gpt = chat_2\n",
    "op.add_persona(char_2)\n",
    "op.send_message(char_1_reply, op.model, maxtoken=maxtoken,printtoken=False)\n",
    "chat_2 = op.chat_thread\n",
    "time.sleep(sleep)\n",
    "    \n",
    "i = 0\n",
    "while i in range(iterations):\n",
    "    \n",
    "    print('\\n'+ char_1+':')\n",
    "    op.chat_gpt = chat_1\n",
    "    op.add_persona(char_1)\n",
    "    op.send_message(op.reply, op.model,\n",
    "                    maxtoken=maxtoken,printtoken=False)\n",
    "    chat_1 = op.chat_thread\n",
    "    time.sleep(sleep)\n",
    "    \n",
    "    print('\\n'+ char_2+':')\n",
    "    op.chat_gpt = chat_2\n",
    "    op.add_persona(char_2)\n",
    "    op.send_message(op.reply, op.model, \n",
    "                    maxtoken=maxtoken,printtoken=False)\n",
    "    chat_2 = op.chat_thread\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.save_chat()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
